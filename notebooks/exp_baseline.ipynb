{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "a117c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import lightning as L\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "00860044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)                   # Python random module\n",
    "    np.random.seed(seed)                # NumPy random seed\n",
    "    torch.manual_seed(seed)             # PyTorch CPU seed\n",
    "    torch.cuda.manual_seed(seed)        # PyTorch CUDA seed\n",
    "    torch.cuda.manual_seed_all(seed)    # All CUDA devices if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True   # For reproducibility\n",
    "    torch.backends.cudnn.benchmark = False      # Disable for reproducibility\n",
    "\n",
    "# Example usage:\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "acf8280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mean = [0.54148953, 0.42486119, 0.37428667]\n",
    "dataset_std = [0.23021227, 0.2072772, 0.1976669 ]\n",
    "\n",
    "class ExpDataset(Dataset):\n",
    "    def __init__(self, imgs_path, csv_path, transform=None):\n",
    "        super().__init__()\n",
    "        self.imgs_path = imgs_path\n",
    "        self.csv_data = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_data)\n",
    "    def __getitem__(self, index):\n",
    "        record = self.csv_data.iloc[index]\n",
    "\n",
    "        img_name = record['image_name']\n",
    "        img_path = os.path.join(self.imgs_path, img_name+\".jpg\")\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transforms to the image\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.Compose([\n",
    "                transforms.Resize((224, 224)).interpolation,\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=dataset_mean, std=dataset_std)\n",
    "            ])(img)\n",
    "        \n",
    "        label = record['expression_label']\n",
    "        return img, label\n",
    "\n",
    "imgs_path = \"../expW/origin_cleaned\"\n",
    "labels_path = \"../expW/new_label.csv\"\n",
    "\n",
    "exp_dataset = ExpDataset(imgs_path, labels_path)\n",
    "N = len(exp_dataset)\n",
    "dataset_range = range(N)\n",
    "\n",
    "train_indices, val_indices = train_test_split(\n",
    "    dataset_range,\n",
    "    train_size=0.8,\n",
    "    random_state=42,\n",
    "    stratify=exp_dataset.csv_data['expression_label']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "b7ed8b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.3521, -2.1307, -2.1307,  ..., -2.1307, -2.1307, -2.1307],\n",
       "         [-2.3521, -2.1307, -2.1307,  ..., -2.1307, -2.1307, -2.1307],\n",
       "         [-2.3521, -2.1307, -2.1307,  ..., -2.1307, -2.1307, -2.1307],\n",
       "         ...,\n",
       "         [-2.3521, -2.3521, -2.3521,  ..., -2.1307, -2.1307, -2.1307],\n",
       "         [-2.3521, -2.3521, -2.3521,  ..., -2.1307, -2.1307, -2.1307],\n",
       "         [-2.3521, -2.3521, -2.3521,  ..., -2.1307, -2.1307, -2.1307]],\n",
       "\n",
       "        [[-2.0497, -1.8038, -1.8038,  ..., -1.8038, -1.8038, -1.8038],\n",
       "         [-2.0497, -1.8038, -1.8038,  ..., -1.8038, -1.8038, -1.8038],\n",
       "         [-2.0497, -1.8038, -1.8038,  ..., -1.8038, -1.8038, -1.8038],\n",
       "         ...,\n",
       "         [-2.0497, -2.0497, -2.0497,  ..., -1.8038, -1.8038, -1.8038],\n",
       "         [-2.0497, -2.0497, -2.0497,  ..., -1.8038, -1.8038, -1.8038],\n",
       "         [-2.0497, -2.0497, -2.0497,  ..., -1.8038, -1.8038, -1.8038]],\n",
       "\n",
       "        [[-1.8935, -1.6356, -1.6356,  ..., -1.6356, -1.6356, -1.6356],\n",
       "         [-1.8935, -1.6356, -1.6356,  ..., -1.6356, -1.6356, -1.6356],\n",
       "         [-1.8935, -1.6356, -1.6356,  ..., -1.6356, -1.6356, -1.6356],\n",
       "         ...,\n",
       "         [-1.8935, -1.8935, -1.8935,  ..., -1.6356, -1.6356, -1.6356],\n",
       "         [-1.8935, -1.8935, -1.8935,  ..., -1.6356, -1.6356, -1.6356],\n",
       "         [-1.8935, -1.8935, -1.8935,  ..., -1.6356, -1.6356, -1.6356]]])"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    # transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.25),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=2.5, translate=(0.05, 0.05), scale=(1.05, 1.05)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=dataset_mean, std=dataset_std)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    # transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=dataset_mean, std=dataset_std)\n",
    "])\n",
    "\n",
    "train_dataset = ExpDataset(imgs_path, labels_path, transform=train_transforms)\n",
    "val_dataset = ExpDataset(imgs_path, labels_path, transform=val_transforms)\n",
    "\n",
    "# Final Splits\n",
    "train_dataset = Subset(train_dataset, train_indices)\n",
    "val_dataset = Subset(val_dataset, val_indices)\n",
    "\n",
    "img, label = train_dataset[36]\n",
    "img\n",
    "# len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "2d8a2d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "881416b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, padding=1, dropout=False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        # Main path\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            padding=padding,\n",
    "            stride=stride,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.dropout1 = nn.Dropout2d(0.05) if dropout else nn.Identity()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            padding=padding,\n",
    "            stride=1,         # always stride=1 for second conv\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.dropout2 = nn.Dropout2d(0.05) if dropout else nn.Identity()\n",
    "\n",
    "        # Shortcut path\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,  # match spatial downsample\n",
    "                    padding=0,\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout1(out)\n",
    "\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.dropout2(out)\n",
    "\n",
    "        out += self.shortcut(identity)\n",
    "        out = self.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "9bdc96fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet3(nn.Module):\n",
    "    def __init__(self, num_classes=7, in_channels=3):\n",
    "        super(Resnet3, self).__init__()\n",
    "\n",
    "        self.initial_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # 224→112→56\n",
    "        )\n",
    "\n",
    "        # Residual layers\n",
    "        self.layer1 = ResidualBlock(in_channels=16, out_channels=32, stride=2)   # 56→28\n",
    "        self.layer2 = ResidualBlock(in_channels=32, out_channels=64, stride=2)   # 28→14\n",
    "        self.layer3 = ResidualBlock(in_channels=64, out_channels=128, stride=2, dropout=True) # 14→7\n",
    "\n",
    "        # Classifier\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_layer(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MulticlassAccuracy \n",
    "\n",
    "class Resnet3Lightning(L.LightningModule):\n",
    "    def __init__(self, num_classes=7, in_channels=3, learning_rate=1e-3, weight_decay=1e-4):\n",
    "        super(Resnet3Lightning, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = Resnet3(num_classes=num_classes, in_channels=in_channels)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.train_acc = MulticlassAccuracy(num_classes=7, average='micro')\n",
    "        self.val_acc = MulticlassAccuracy(num_classes=7, average='micro')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.train_acc.update(preds, y)\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        \n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_acc.update(preds, y)\n",
    "\n",
    "        self.log('val_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        avg_train_loss = self.trainer.callback_metrics.get('train_loss')\n",
    "        accuracy = self.train_acc.compute().item()\n",
    "        print(f\"Epoch {self.current_epoch+1} TRAIN loss: {avg_train_loss:.4f} | Train Accuracy: {accuracy:.4f}\")\n",
    "        self.train_acc.reset()\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_val_loss = self.trainer.callback_metrics.get('val_loss')\n",
    "        accuracy = self.val_acc.compute().item()\n",
    "        print(f\"Epoch {self.current_epoch+1} VALIDATION loss: {avg_val_loss:.4f} | Val Accuracy: {accuracy:.4f}\")\n",
    "        self.val_acc.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=15, eta_min=1e-6)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            'lr_scheduler': {\n",
    "                \"scheduler\": lr_scheduler,\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "334415da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "class CustomProgressBar(TQDMProgressBar):\n",
    "    def init_train_tqdm(self):\n",
    "        bar = super().init_train_tqdm()\n",
    "        bar.set_description(\"🔥 Training is running!\")\n",
    "        return bar\n",
    "    def init_validation_tqdm(self):\n",
    "        bar = super().init_validation_tqdm()\n",
    "        bar.set_description(\"💧 Validating on validation set\")\n",
    "        return bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b47427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | Resnet3            | 305 K  | train\n",
      "1 | criterion | CrossEntropyLoss   | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "305 K     Trainable params\n",
      "0         Non-trainable params\n",
      "305 K     Total params\n",
      "1.223     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa03baa8cba14ffc81cdd567def48851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\emotion_project\\venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 VALIDATION loss: 1.9761 | Val Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\emotion_project\\venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50737c12eed468883284e765a11fc4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8f226233c94505aa2ac3a895c781be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 VALIDATION loss: 1.2142 | Val Accuracy: 0.5690\n",
      "Epoch 1 TRAIN loss: 1.3762 | Train Accuracy: 0.4765\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328aa9a3d82f4f2498368847dcee3f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 VALIDATION loss: 1.0704 | Val Accuracy: 0.6256\n",
      "Epoch 2 TRAIN loss: 1.1405 | Train Accuracy: 0.5981\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bd3d1965054fe085fee7db921392a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 VALIDATION loss: 1.0071 | Val Accuracy: 0.6479\n",
      "Epoch 3 TRAIN loss: 1.0510 | Train Accuracy: 0.6321\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f35155270c642438dfbb7aa03a2333b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 VALIDATION loss: 0.9911 | Val Accuracy: 0.6554\n",
      "Epoch 4 TRAIN loss: 1.0041 | Train Accuracy: 0.6481\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3665b80734e54c8a9d20f7b0e4210f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 VALIDATION loss: 0.9638 | Val Accuracy: 0.6647\n",
      "Epoch 5 TRAIN loss: 0.9730 | Train Accuracy: 0.6587\n"
     ]
    }
   ],
   "source": [
    "model = Resnet3Lightning().to(device=\"cuda\")\n",
    "trainer = L.Trainer(\n",
    "    accelerator='gpu',\n",
    "    log_every_n_steps=1,\n",
    "    max_epochs=15,\n",
    "    precision=\"16-mixed\",\n",
    "    devices=1,\n",
    "    logger=None,\n",
    "    num_sanity_val_steps=1,\n",
    "    callbacks=[CustomProgressBar()]\n",
    ")\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17d8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
